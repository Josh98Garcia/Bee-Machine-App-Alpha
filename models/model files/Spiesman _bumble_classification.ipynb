{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network for bumble bee species ID from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # I'm using tf v1.13.1\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import random\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D, AveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data directory and names of species included in the classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"C:/Bombus_images_cropped\"\n",
    "CATEGORIES = [\"Bombus_affinis\", \"Bombus_appositus\", \"Bombus_auricomus\", \"Bombus_bifarius\", \"Bombus_bimaculatus\", \"Bombus_borealis\", \n",
    "             \"Bombus_caliginosus\", \"Bombus_centralis\", \"Bombus_citrinus\", \"Bombus_crotchii\", \"Bombus_cryptarum\", \"Bombus_fernaldae_flavidus\", \n",
    "             \"Bombus_fervidus\", \"Bombus_flavifrons\", \"Bombus_fraternus\", \"Bombus_frigidus\", \"Bombus_griseocollis\", \"Bombus_huntii\", \n",
    "             \"Bombus_impatiens\", \"Bombus_insularis\", \"Bombus_melanopygus\", \"Bombus_mixtus\", \"Bombus_morrisoni\", \"Bombus_nevadensis\", \n",
    "             \"Bombus_occidentalis\", \"Bombus_pensylvanicus_sonorus\", \"Bombus_perplexus\",\"Bombus_rufocinctus\", \"Bombus_sandersoni\",\n",
    "             \"Bombus_sitkensis\", \"Bombus_sylvicola\", \"Bombus_ternarius\", \"Bombus_terricola\", \"Bombus_vagans\", \"Bombus_vandykei\", \n",
    "             \"Bombus_vosnesenskii\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set number of classes (species) and image size (number of pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(CATEGORIES)\n",
    "IMG_SIZE = 299 #length and width of input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "img_filenames = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "      path=os.path.join(DATADIR,category)\n",
    "      class_num = CATEGORIES.index(category)\n",
    "      for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
    "            training_data.append([new_array, class_num])\n",
    "            img_filenames.append(os.path.join(path,img))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and resize the image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42) #split into training and test data\n",
    "img_file_train, img_file_test = train_test_split(img_filenames, test_size=0.2, random_state=42) #split into training and test data\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data are imbalanaced. Set up class weights to help account for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "weights_dict = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size and data augmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=100,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras_applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.applications import MobileNetV2\n",
    "\n",
    "# InceptionV3 performed best of the models above \n",
    "base_model = InceptionV3(include_top=False, pooling ='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.06)(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.06)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up early stopping, save best model, adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-3 accuracy can be included in metrics\n",
    "top3_acc = functools.partial(keras.metrics.sparse_top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"sgd\", \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epocs = 50\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                              epochs=num_epocs,\n",
    "                              validation_data=(X_test, y_test),  \n",
    "                              verbose=1,\n",
    "                              class_weight=weights_dict,\n",
    "                              callbacks=[mcp_save, reduce_lr_loss],\n",
    "                              use_multiprocessing=False,\n",
    "                              workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_x_date.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss and accuracy\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print ('Accuracy Score:',accuracy_score(y_test, y_pred_labels))\n",
    "print(classification_report(y_test, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at a random test image and see prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_images = 1\n",
    "rand_images = []\n",
    "for i in range(0,num_images):\n",
    "    n = random.randint(1,15431)\n",
    "    rand_images.append(n)\n",
    "\n",
    "for x in rand_images:\n",
    "    y_pred = model.predict(X_test[[x]])\n",
    "    y_pred_labels = np.argmax(y_pred)\n",
    "    plt.imshow(X_test[x])\n",
    "    print('Test image:',x)\n",
    "    print('True species:',CATEGORIES[y_test[x]])\n",
    "    print('Predicted species:',CATEGORIES[y_pred_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make table of misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image = ['Test image']\n",
    "true_species = ['True species']\n",
    "pred_species = ['Predicted species']\n",
    "probability = ['Probability']\n",
    "img_file_name = ['File name']\n",
    "\n",
    "test_images = list(range(len(X_test)))\n",
    "for x in test_images:\n",
    "    y_pred = model.predict(X_test[[x]])\n",
    "    y_pred_labels = np.argmax(y_pred)\n",
    "    if y_test[x] != y_pred_labels:\n",
    "        test_image.append(x)\n",
    "        true_species.append(CATEGORIES[y_test[x]])\n",
    "        pred_species.append(CATEGORIES[y_pred_labels])\n",
    "        probability.append(max(max(model.predict(X_test[[x]]))))\n",
    "        img_file_name.append(img_file_test[x])\n",
    "\n",
    "true_pred_species = list(zip(test_image, true_species, pred_species, probability, img_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save misclassification table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('true_pred_species', true_pred_species, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image and results from a particular test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 221\n",
    "y_pred = model.predict(X_test[[image_num]])\n",
    "y_pred_labels = np.argmax(y_pred)\n",
    "plt.imshow(X_test[image_num])\n",
    "print('Test image:',image_num)\n",
    "print('True species:',CATEGORIES[y_test[image_num]])\n",
    "print('Predicted species:',CATEGORIES[y_pred_labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
